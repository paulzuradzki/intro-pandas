{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2\n",
    "* Formatting data\n",
    "* Profiling data continued\n",
    "    * Missing data\n",
    "    * Unique values and counts\n",
    "    * De-duplicating\n",
    "* Clean missing data\n",
    "* Group By operations and reshaping data\n",
    "* Combining data and merging (joining) data\n",
    "* Rolling / window functions and lead/lag shift\n",
    "* Custom functions - apply/applymap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# custom module for this tutorial\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading searborn datasets\n",
    "utils.prep_example_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading trip history data from Divvy bikeshare\n",
    "# docs: https://www.divvybikes.com/system-data\n",
    "\n",
    "divvy_urls = ['https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_2019_Q1.zip',\n",
    "       'https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_2019_Q2.zip',\n",
    "       'https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_2019_Q3.zip',\n",
    "       'https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_2019_Q4.zip']\n",
    "\n",
    "# this may take 1-2 minutes. Downloading 4 CSV files.\n",
    "for url in divvy_urls:\n",
    "#     utils.process_url_zip(url=url, zip_name='divvy.zip', target_path='./data')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that data files are there\n",
    "\n",
    "os.listdir('./data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep - load and profile data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy = pd.read_csv('./data/Divvy_Trips_2019_Q1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect top 5 rows\n",
    "divvy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check size and object types\n",
    "divvy.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top 10 birthyears and check NAs\n",
    "# pd.NaN is numpy object for null values\n",
    "divvy['birthyear'].value_counts(dropna=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy['gender'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map words to abbreviation\n",
    "\n",
    "gender_map = {'Male': 'M', 'Female': 'F'}\n",
    "divvy['gender2'] = divvy['gender'].map(gender_map)\n",
    "# divvy['gender2'] = divvy['gender'].map({'Male': 'M', 'Female': 'F'})\n",
    "\n",
    "divvy.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting data types with `.astype(<type>)`\n",
    "\n",
    "This throws an error...\n",
    "\n",
    "`divvy['birthyear2'] = divvy['birthyear'].astype(int)`\n",
    "\n",
    "```\n",
    "ValueError                                Traceback (most recent call last)\n",
    "<ipython-input-27-3b2a21753e03> in <module>\n",
    "----> 1 divvy['birthyear2'] = divvy['birthyear'].astype(int)\n",
    "...\n",
    "ValueError: Cannot convert non-finite values (NA or inf) to integer\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill nulls with 0, then convert to int\n",
    "    # we'll cover fillna() and dropna() later\n",
    "    \n",
    "divvy['birthyear2'] = divvy['birthyear'].fillna(0).astype(int)\n",
    "divvy.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract streetnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will parse the station names\n",
    "divvy['from_station_name'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pandas, remember to access .str attribute to make string methods available\n",
    "    # else you will get this error --> `AttributeError: 'Series' object has no attribute 'split'`\n",
    "\n",
    "divvy['from_station_name'].str.split(' & ').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy['from_station_name'].str.split(' & ', expand=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy[['from_x', 'from_y']] = divvy['from_station_name'].str.split(' & ', expand=True)\n",
    "divvy[['from_x', 'from_y']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String search and regex pattern matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_bool is a Series of True/False's\n",
    "# pass to bracket [] of dataframe for boolean indexing/filtering\n",
    "\n",
    "# filter to where station contains Dearborn in name\n",
    "search_bool = divvy['from_station_name'].str.contains('Dearborn')\n",
    "divvy[search_bool].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use of not (~) operator\n",
    "no_and_character_bool = ~(divvy['from_station_name'].str.contains('&'))\n",
    "divvy[no_and_character_bool].loc[:, 'from_station_name'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use regex search via Series.str.contains(<pattern>, regex=True)\n",
    "\n",
    "regex_bool = divvy['from_station_name'].str.contains('Pkwy|Pl', regex=True)\n",
    "divvy[regex_bool].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert continous variables to categories (binning data)\n",
    "\n",
    "If you want equal distribution of the items in your bins, use `qcut` . If you want to define your own numeric bin ranges, then use `cut`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create age column\n",
    "    # more on date formatting later\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "current_year = datetime.now().year\n",
    "print(f'current year is: {current_year}')\n",
    "\n",
    "divvy['age'] = current_year - divvy['birthyear']\n",
    "divvy[['birthyear', 'age']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy['age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut into 4 intervales of equal size\n",
    "\n",
    "divvy['age_interval'] = pd.qcut(divvy['age'], q=4)\n",
    "divvy['age_interval'].value_counts(dropna=False, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy[['age', 'age_interval']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cutting into quintiles\n",
    "bin_labels = ['bottom third', 'middle third', 'upper third'] \n",
    "divvy['age_interval2'] = pd.qcut(divvy['age'], q=[0, .33, .66, 1], labels=bin_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample random 10\n",
    "divvy[['age', 'age_interval2']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intervals of eqaul size intervals -- but un-equal distributions\n",
    "\n",
    "pd.cut(divvy['age'], bins=4).value_counts(dropna=False, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting datetimes\n",
    "\n",
    "Notes\n",
    "* pandas/numpy datetime64 data type is more efficient than native Python datetime vie `datetime` standard library\n",
    "* try to convert to pandas datetime64 if you're doing computations on many dates (ex: dates in a dataset)\n",
    "* docs: https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy['start_time'] = pd.to_datetime(divvy['start_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, using `.dt.` attribute, we can access datetime-like attributes too\n",
    "\n",
    "divvy['start_day'] = divvy['start_time'].dt.day\n",
    "divvy['start_month'] = divvy['start_time'].dt.month\n",
    "divvy['start_hour'] = divvy['start_time'].dt.hour\n",
    "\n",
    "divvy[['start_time', 'start_day', 'start_month', 'start_hour']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can plot frequency by hour\n",
    "\n",
    "divvy['start_hour'].value_counts(normalize=True)\\\n",
    "                   .sort_index()\\\n",
    "                   .plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculated fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tripduration is a string... to do math, we want it to be a float or int\n",
    "\n",
    "divvy['tripduration'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert string to float: replace commas, replace '.0', then cast to float\n",
    "divvy['tripduration'] = divvy['tripduration'].str.replace(',', '')\\\n",
    "                                             .str.replace('.0','')\\\n",
    "                                             .replace('','0')\\\n",
    "                                             .astype(int)\n",
    "\n",
    "# make new tripduration field that converts minutes to hours\n",
    "divvy['tripduration_hrs'] = divvy['tripduration'] / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy[['tripduration', 'tripduration_hrs']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .describe() can be used on sub-selection\n",
    "# .T for transpose\n",
    "\n",
    "divvy[['gender', 'age']].describe(include='all').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique values via drop_duplicates or numpy .unique()\n",
    "\n",
    "divvy['from_station_name'].drop_duplicates()\n",
    "# divvy['from_station_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of unique values\n",
    "\n",
    "divvy['from_station_name'].nunique()\n",
    "# divvy['from_station_name'].drop_duplicates().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De-duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = pd.DataFrame([['John', 'Doe', '123 Main St'],\n",
    "                     ['John', 'Doe', '999 Wall St'],\n",
    "                     ['John', 'Doe', '123 Main St'],\n",
    "                     ['Jane', 'Dee', '1 Pennsylvania'],\n",
    "                     ['Jane', 'Dee', 'Dearborn / Erie'],\n",
    "                     ['Mike', 'Jones', 'Palmer House']], columns=['first', 'last', 'address'])\n",
    "\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dedupe at level of first-last name\n",
    "# arbitrarily keep first address (can sort if applicable)\n",
    "\n",
    "deduped_names = names.drop_duplicates(subset=['first', 'last'], keep='first')\n",
    "deduped_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dupes across all columns\n",
    "# John Doe @ 123 Main St exists twice in original\n",
    "    # Jane Dee exists twice but at different addresses\n",
    "\n",
    "names[names.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dupes across subset of columns\n",
    "\n",
    "dupes = names[names.duplicated(subset=['first', 'last'])]\n",
    "dupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique list of first-last names that are duplicated\n",
    "\n",
    "names.iloc[dupes.index].loc[:,['first', 'last']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group By operations and reshaping data\n",
    "* df.groupby()\n",
    "* df.pivot_table()\n",
    "* df.melt()\n",
    "* pd.crosstab()\n",
    "* df.T\n",
    "\n",
    "* note: caution on NAs. Fill NAs in grouping columns prior to grouping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining data and merging (joining) data\n",
    "* pd.concat()\n",
    "* df.merge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rolling / window functions and lead/lag shift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# # formatted\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# sns.set()\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(15,5))\n",
    "# divvy['start_hour'].value_counts(normalize=True)\\\n",
    "#                    .sort_index()\\\n",
    "#                    .plot(kind='bar')\n",
    "\n",
    "# ax.set_title('Bike Ridership by Hour of Day', fontsize='large')\n",
    "# ax.set_xlabel('Hour of Day')\n",
    "# ax.set_ylabel('Percentage of Riders')\n",
    "# xlabels = divvy['start_hour'].unique().tolist()\n",
    "# plt.xticks(rotation='horizontal')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
